LLM_MODELS = {
    "OpenAI GPT-4o": "gpt-4o-mini",
    "Gemma 3 (4B) Instruct - 4-bit quantized": "unsloth/gemma-3-4b-it-unsloth-bnb-4bit",
    "Gemma 3 (4B) Instruct":  "unsloth/gemma-3-4b-it",
    "Gemma 2 (9B) Instruct":  "gemma2-9b-it",
    "Llama 3.1 (8B) Instruct - 4-bit quantized":  "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
    "Llama 3.1 (8B) Instruct":  "unsloth/Meta-Llama-3.1-8B-Instruct",
    "Mistral (7B) Instruct v0.3": "mistralai/Mistral-7B-Instruct-v0.3",
    "Gemma 3 (4B) Instruct - Fine-tuned for better Q&A about ArXiv papers": "mieng155/gemma-3-4b-it-arxiv-instruct-qlora",
    "Gemma 3 (4B) Instruct - Fine-tuned for German Q&A": "mieng155/gemma-3-4b-it-german-alpaca-qlora",
    "Llama 3.1 (8B) Instruct - Fine-tuned for German Q&A": "mieng155/llama-3-1-8b-german-alpaca-qlora",
} 